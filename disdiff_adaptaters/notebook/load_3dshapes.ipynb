{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a040381",
   "metadata": {},
   "source": [
    "# Play with 3dshapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d881f",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777670e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/.cache/pypoetry/virtualenvs/disdiff-adaptaters-m1Sdj2Jl-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexandre/.cache/pypoetry/virtualenvs/disdiff-adaptaters-m1Sdj2Jl-py3.10/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/home/alexandre/.cache/pypoetry/virtualenvs/disdiff-adaptaters-m1Sdj2Jl-py3.10/lib/python3.10/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/home/alexandre/.cache/pypoetry/virtualenvs/disdiff-adaptaters-m1Sdj2Jl-py3.10/lib/python3.10/site-packages/timm/optim/optim_factory.py:7: FutureWarning: Importing from timm.optim.optim_factory is deprecated, please import via timm.optim\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.optim\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_PATH=\"/home/alexandre/disdiff_adaptaters\"\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "import lightning as L\n",
    "from lightning import LightningDataModule, LightningModule\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from disdiff_adaptaters.data_module.shapes3d import Shapes3DDataModule\n",
    "from disdiff_adaptaters.utils.utils import load_h5\n",
    "from disdiff_adaptaters.utils.const import Shapes3D\n",
    "\n",
    "from src.backbones.vit.chada_vit import ChAdaViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb34d3c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75b2f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 64, 3) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_h5(Shapes3D.Path.H5)\n",
    "images = images[:100]\n",
    "labels = labels[:100]\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dac60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True \n",
    "if not local :\n",
    "    data_module = Shapes3DDataModule()\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup(stage='fit')\n",
    "    train_loader = data_module.train_dataloader()\n",
    "else :\n",
    "    images, labels = load_h5(Shapes3D.Path.H5)\n",
    "    images = images[:100]\n",
    "    labels = labels[:100]\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(images).permute(0,3,1,2), torch.tensor(labels)), batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786439b6",
   "metadata": {},
   "source": [
    "## Load encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fb92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "PATCH_SIZE = 16\n",
    "EMBED_DIM = 192\n",
    "RETURN_ALL_TOKENS = False\n",
    "MAX_NUMBER_CHANNELS = 10\n",
    "\n",
    "CKPT_PATH = \"/home/alexandre/disdiff_adaptaters/disdiff_adaptaters/arch/Dino-IDRCell100k-vit_c-embed_dim_192_patch_16-310682-ep=399.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64d7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChAdaViT(\n",
    "    patch_size=PATCH_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    return_all_tokens=RETURN_ALL_TOKENS,\n",
    "    max_number_channels=MAX_NUMBER_CHANNELS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a02336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChAdaViT(\n",
       "  (token_learner): TokenLearner(\n",
       "    (proj): Conv2d(1, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(CKPT_PATH, map_location=\"cpu\", weights_only=False)[\"state_dict\"]\n",
    "for k in list(state.keys()):\n",
    "    if \"encoder\" in k:\n",
    "        state[k.replace(\"encoder\", \"backbone\")] = state[k]\n",
    "    if \"backbone\" in k:\n",
    "        state[k.replace(\"backbone.\", \"\")] = state[k]\n",
    "    del state[k]\n",
    "model.load_state_dict(state, strict=False)\n",
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875ea4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader : \n",
    "    images, labels = batch\n",
    "    model((images/255.0).to(torch.float32)[:,1,:,:].unsqueeze(1), index=0, list_num_channels=len(images)*[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d773fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disdiff-adaptaters-m1Sdj2Jl-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
