from lightning import LightningDataModule
from torch.utils.data import DataLoader
import numpy as np

from os.path import exists

from disdiff_adapters.dataset import DSpritesDataset
from disdiff_adapters.utils.utils import load_h5, split
from disdiff_adapters.utils.const import DSprites


class DSpritesDataModule(LightningDataModule):
    def __init__(
        self,
        h5_path: str = DSprites.Path.H5,
        train_path: str = DSprites.Path.TRAIN,
        val_path: str = DSprites.Path.VAL,
        test_path: str = DSprites.Path.TEST,
        ratio: int = 0.8,
        batch_size: int = 8,
        loader: DataLoader | None = None,
    ):
        super().__init__()
        self.h5_path = h5_path
        self.train_path, self.val_path, self.test_path = train_path, val_path, test_path
        self.ratio = ratio
        self.batch_size = batch_size
        self.loader = loader

    def prepare_data(self, is_h5: bool = False):
        if not (
            exists(self.train_path) and exists(self.val_path) and exists(self.test_path)
        ):
            if is_h5:
                print("h5 file loading.")
                images, labels = load_h5(self.h5_path)
                train_images, train_labels, test_images, test_labels = split(
                    images, labels
                )
                train_images, train_labels, val_images, val_labels = split(
                    train_images, train_labels
                )
            else:
                data = np.load(DSprites.Path.NPZ)
                train_images = data["imgs"]
                train_labels = data["latents_classes"]

                train_images, train_labels, test_images, test_labels = split(
                    train_images, train_labels
                )
                train_images, train_labels, val_images, val_labels = split(
                    train_images, train_labels
                )

            np.savez(self.train_path, images=train_images, labels=train_labels)
            np.savez(self.val_path, images=val_images, labels=val_labels)
            np.savez(self.test_path, images=test_images, labels=test_labels)

        else:
            pass

    def setup(self, stage: str | None):
        # data = np.load(DSprites.Path.NPZ)
        if stage in ("fit", None):
            train_images, train_labels = (
                np.load(self.train_path)["images"],
                np.load(self.train_path)["labels"],
            )
            val_images, val_labels = (
                np.load(self.val_path)["images"],
                np.load(self.val_path)["labels"],
            )
            # train_labels = data["train_labels.npy"]

            # train_images, train_labels, val_images, val_labels = split(train_images, train_labels)

            # print("loading of tensors - train")
            # train_images, train_labels = torch.load(self.train_path)
            # print("loading of tensors - val")
            # val_images, val_labels = torch.load(self.val_path)

            print("load dataset - train")
            self.train_dataset = DSpritesDataset(train_images, train_labels)
            print("load dataset val")
            self.val_dataset = DSpritesDataset(val_images, val_labels)
        else:
            # test_images = data["test_images.npy"]
            # test_labels = data["test_labels.npy"]

            # test_images, test_labels = torch.load(self.test_path)
            test_images, test_labels = (
                np.load(self.test_path)["images"],
                np.load(self.test_path)["labels"],
            )
            self.test_dataset = DSpritesDataset(test_images, test_labels)
        print("tensors loaded.")
        self.set_dataloader(self.loader)

    def train_dataloader(self):
        if self.loader is None:
            return DataLoader(
                self.train_dataset,
                batch_size=self.batch_size,
                num_workers=16,
                shuffle=True,
            )
        else:
            return self.loader

    def val_dataloader(self):
        return DataLoader(
            self.val_dataset, batch_size=self.batch_size, num_workers=16, shuffle=True
        )

    def test_dataloader(self):
        return DataLoader(
            self.test_dataset, batch_size=self.batch_size, num_workers=16, shuffle=True
        )

    def set_dataloader(self, loader: DataLoader | None):
        self.loader = loader
